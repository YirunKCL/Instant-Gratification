{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LIBRARIES\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn.gaussian_process.kernels as ker\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np, pandas as pd, os, gc\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.covariance import GraphicalLasso\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_cov(x,y):\n",
    "    model = GraphicalLasso()\n",
    "    ones = (y==1).astype(bool)\n",
    "    x2 = x[ones]\n",
    "    model.fit(x2)\n",
    "    p1 = model.precision_\n",
    "    m1 = model.location_\n",
    "    \n",
    "    onesb = (y==0).astype(bool)\n",
    "    x2b = x[onesb]\n",
    "    model.fit(x2b)\n",
    "    p2 = model.precision_\n",
    "    m2 = model.location_\n",
    "    \n",
    "    ms = np.stack([m1,m2])\n",
    "    ps = np.stack([p1,p2])\n",
    "    return ms,ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Train Data...\n",
      "Reading Test Data...\n",
      "Finish Reading.\n"
     ]
    }
   ],
   "source": [
    "print('Reading Train Data...')\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "print('Reading Test Data...')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "print('Finish Reading.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a808c21561b5426483003692c08ce8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GMM oof auc :  0.96445\n",
      "0 SVC oof auc :  0.94854\n",
      "0 KNN oof auc :  0.93811\n",
      "0 LR oof auc :  0.94131\n",
      "0 MLP oof auc :  0.93307\n",
      "64 GMM oof auc :  0.98259\n",
      "64 SVC oof auc :  0.97359\n",
      "64 KNN oof auc :  0.94103\n",
      "64 LR oof auc :  0.97915\n",
      "64 MLP oof auc :  0.97076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.844e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.620e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.436e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 GMM oof auc :  0.97308\n",
      "128 SVC oof auc :  0.95673\n",
      "128 KNN oof auc :  0.93469\n",
      "128 LR oof auc :  0.96028\n",
      "128 MLP oof auc :  0.94864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.558e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.137e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 GMM oof auc :  0.98051\n",
      "192 SVC oof auc :  0.9637\n",
      "192 KNN oof auc :  0.93334\n",
      "192 LR oof auc :  0.96721\n",
      "192 MLP oof auc :  0.95764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.404e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 GMM oof auc :  0.98403\n",
      "256 SVC oof auc :  0.97598\n",
      "256 KNN oof auc :  0.94539\n",
      "256 LR oof auc :  0.97192\n",
      "256 MLP oof auc :  0.96092\n",
      "320 GMM oof auc :  0.95287\n",
      "320 SVC oof auc :  0.94078\n",
      "320 KNN oof auc :  0.92212\n",
      "320 LR oof auc :  0.93753\n",
      "320 MLP oof auc :  0.93218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: -1.683e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: -2.110e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 GMM oof auc :  0.96329\n",
      "384 SVC oof auc :  0.9423\n",
      "384 KNN oof auc :  0.91666\n",
      "384 LR oof auc :  0.94985\n",
      "384 MLP oof auc :  0.95015\n",
      "448 GMM oof auc :  0.97794\n",
      "448 SVC oof auc :  0.97629\n",
      "448 KNN oof auc :  0.93805\n",
      "448 LR oof auc :  0.95899\n",
      "448 MLP oof auc :  0.94768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.055e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.647e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.051e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.351e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.092e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.347e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.763e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE VARIABLES\n",
    "oof_SVC = np.zeros(len(train))\n",
    "# oof_NuSVC = np.zeros(len(train))\n",
    "oof_KNN = np.zeros(len(train))\n",
    "oof_GMM = np.zeros(len(train))\n",
    "oof_LR = np.zeros(len(train))\n",
    "oof_MLP = np.zeros(len(train))\n",
    "\n",
    "preds_SVC = np.zeros(len(test))\n",
    "# preds_NuSVC = np.zeros(len(test))\n",
    "preds_KNN = np.zeros(len(test))\n",
    "preds_GMM = np.zeros(len(test))\n",
    "preds_LR = np.zeros(len(test))\n",
    "preds_MLP = np.zeros(len(test))\n",
    "\n",
    "cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "\n",
    "# BUILD 512 SEPARATE NON-LINEAR MODELS\n",
    "for i in tqdm_notebook(range(512)):\n",
    "    \n",
    "    # EXTRACT SUBSET OF DATASET WHERE WHEEZY-MAGIC EQUALS I\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    idx1 = train2.index; idx2 = test2.index\n",
    "    train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n",
    "    train3 = sel.transform(train2[cols])\n",
    "    test3 = sel.transform(test2[cols])\n",
    "    \n",
    "    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "    data2 = StandardScaler().fit_transform(PCA(svd_solver='full',n_components='mle').fit_transform(data[cols]))\n",
    "    train4 = data2[:train2.shape[0]]; test4 = data2[train2.shape[0]:]\n",
    "    \n",
    "    poly = PolynomialFeatures(2)\n",
    "    sc = StandardScaler()\n",
    "    data3 = poly.fit_transform(sc.fit_transform(VarianceThreshold(threshold=1.5).fit_transform(data[cols])))\n",
    "    train5 = data3[:train2.shape[0]]; test5 = data3[train2.shape[0]:]\n",
    "        \n",
    "    # STRATIFIED K FOLD (Using splits=25 scores 0.002 better but is slower)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, random_state=42)\n",
    "    for train_index, test_index in skf.split(train3, train2['target']):\n",
    "        \n",
    "        # MODEL WITH GMM\n",
    "        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values) \n",
    "        gm = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "        gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n",
    "        oof_GMM[idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:,0]\n",
    "        preds_GMM[idx2] += gm.predict_proba(test3)[:,0] / skf.n_splits\n",
    "        \n",
    "        # OTHER MODELS\n",
    "        clf_SVC = SVC(probability=True,kernel='poly',degree=4,gamma='auto')\n",
    "#         clf_NuSVC = NuSVC(probability=True,kernel='poly',degree=4,gamma='auto',nu=0.59, coef0=0.053)\n",
    "        clf_KNN = KNeighborsClassifier(n_neighbors=10,weights='distance',p=2)\n",
    "        clf_LR = LogisticRegression(solver='saga',penalty='l2',C=0.01,tol=0.001)\n",
    "        clf_MLP = MLPClassifier(activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(250,), random_state=42)\n",
    "        \n",
    "        clf_SVC.fit(train4[train_index,:],train2.loc[train_index]['target'])\n",
    "#         clf_NuSVC.fit(train4[train_index,:],train2.loc[train_index]['target'])\n",
    "        clf_KNN.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        clf_LR.fit(train5[train_index,:],train2.loc[train_index]['target'])\n",
    "        clf_MLP.fit(train5[train_index,:],train2.loc[train_index]['target'])\n",
    "        \n",
    "        oof_SVC[idx1[test_index]] = clf_SVC.predict_proba(train4[test_index,:])[:,1]\n",
    "#         oof_NuSVC[idx1[test_index]] = clf_NuSVC.predict_proba(train4[test_index,:])[:,1]\n",
    "        oof_KNN[idx1[test_index]] = clf_KNN.predict_proba(train3[test_index,:])[:,1]\n",
    "        oof_LR[idx1[test_index]] = clf_LR.predict_proba(train5[test_index,:])[:,1]\n",
    "        oof_MLP[idx1[test_index]] = clf_MLP.predict_proba(train5[test_index,:])[:,1]\n",
    "        \n",
    "        preds_SVC[idx2] += clf_SVC.predict_proba(test4)[:,1] / skf.n_splits\n",
    "#         preds_NuSVC[idx2] += clf_NuSVC.predict_proba(test4)[:,1] / skf.n_splits\n",
    "        preds_KNN[idx2] += clf_KNN.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        preds_LR[idx2] += clf_LR.predict_proba(test5)[:,1] / skf.n_splits\n",
    "        preds_MLP[idx2] += clf_MLP.predict_proba(test5)[:,1] / skf.n_splits\n",
    "        \n",
    "    if i%64==0:     \n",
    "        print(i, 'GMM oof auc : ', round(roc_auc_score(train['target'][idx1], oof_GMM[idx1]), 5))\n",
    "        print(i, 'SVC oof auc : ', round(roc_auc_score(train['target'][idx1], oof_SVC[idx1]), 5))\n",
    "#         print(i, 'NuSVC oof auc : ', round(roc_auc_score(train['target'][idx1], oof_NuSVC[idx1]), 5))\n",
    "        print(i, 'KNN oof auc : ', round(roc_auc_score(train['target'][idx1], oof_KNN[idx1]), 5))\n",
    "        print(i, 'LR oof auc : ', round(roc_auc_score(train['target'][idx1], oof_LR[idx1]), 5))\n",
    "        print(i, 'MLP oof auc : ', round(roc_auc_score(train['target'][idx1], oof_MLP[idx1]), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM auc:  0.96874\n",
      "SVC auc:  0.95515\n",
      "KNN auc:  0.92928\n",
      "LR auc:  0.95003\n",
      "MLP auc:  0.94012\n"
     ]
    }
   ],
   "source": [
    "auc_GMM = roc_auc_score(train['target'],oof_GMM)\n",
    "print('GMM auc: ',round(auc_GMM,5))\n",
    "\n",
    "auc_SVC = roc_auc_score(train['target'],oof_SVC)\n",
    "print('SVC auc: ',round(auc_SVC,5))\n",
    "\n",
    "# auc_NuSVC = roc_auc_score(train['target'],oof_NuSVC)\n",
    "# print('NuSVC auc: ',round(auc_NuSVC,5))\n",
    "\n",
    "auc_KNN = roc_auc_score(train['target'],oof_KNN)\n",
    "print('KNN auc: ',round(auc_KNN,5))\n",
    "\n",
    "auc_LR = roc_auc_score(train['target'],oof_LR)\n",
    "print('LR auc: ',round(auc_LR,5))\n",
    "\n",
    "auc_MLP = roc_auc_score(train['target'],oof_MLP)\n",
    "print('MLP auc: ',round(auc_MLP,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a33468800044a4a5158be6093c4e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 QDA oof auc :  0.9633\n",
      "0 NuSVC oof auc :  0.96699\n",
      "64 QDA oof auc :  0.98281\n",
      "64 NuSVC oof auc :  0.98025\n",
      "128 QDA oof auc :  0.97261\n",
      "128 NuSVC oof auc :  0.97108\n",
      "192 QDA oof auc :  0.98081\n",
      "192 NuSVC oof auc :  0.98671\n",
      "256 QDA oof auc :  0.98388\n",
      "256 NuSVC oof auc :  0.98239\n",
      "320 QDA oof auc :  0.95147\n",
      "320 NuSVC oof auc :  0.95096\n",
      "384 QDA oof auc :  0.96377\n",
      "384 NuSVC oof auc :  0.9533\n",
      "448 QDA oof auc :  0.97891\n",
      "448 NuSVC oof auc :  0.97996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE VARIABLES\n",
    "test['target'] = preds_GMM\n",
    "oof_QDA = np.zeros(len(train))\n",
    "preds_QDA = np.zeros(len(test))\n",
    "\n",
    "oof_NuSVC = np.zeros(len(train))\n",
    "preds_NuSVC = np.zeros(len(test))\n",
    "\n",
    "# BUILD 512 SEPARATE MODELS\n",
    "for k in tqdm_notebook(range(512)):\n",
    "    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==k] \n",
    "    train2p = train2.copy(); idx1 = train2.index \n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==k]\n",
    "    \n",
    "    # ADD PSEUDO LABEL DATA\n",
    "    test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n",
    "    test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n",
    "    test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n",
    "    train2p = pd.concat([train2p,test2p],axis=0)\n",
    "    train2p.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "    sel = VarianceThreshold(threshold=1.5).fit(train2p[cols])     \n",
    "    train3p = sel.transform(train2p[cols])\n",
    "    train3 = sel.transform(train2[cols])\n",
    "    test3 = sel.transform(test2[cols])\n",
    "    \n",
    "    pca = PCA(svd_solver='full',n_components='mle').fit(train2p[cols])\n",
    "    train4p = pca.transform(train2p[cols])\n",
    "    train4 = pca.transform(train2[cols])\n",
    "    test4 = pca.transform(test2[cols])\n",
    "    sc1 = StandardScaler()\n",
    "    train4p = sc1.fit_transform(train4p)\n",
    "    train4 = sc1.transform(train4)\n",
    "    test4 = sc1.transform(test4)\n",
    "        \n",
    "    # STRATIFIED K FOLD\n",
    "    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(train3p, train2p['target']):\n",
    "        test_index3 = test_index[ test_index<len(train3) ] # ignore psuedo in oof\n",
    "        \n",
    "        # MODEL AND PREDICT WITH QDA\n",
    "        clf_QDA = QuadraticDiscriminantAnalysis(reg_param=0.5)\n",
    "        clf_QDA.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n",
    "        oof_QDA[idx1[test_index3]] = clf_QDA.predict_proba(train3[test_index3,:])[:,1]\n",
    "        preds_QDA[test2.index] += clf_QDA.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf_NuSVC = NuSVC(probability=True,kernel='poly',degree=4,gamma='auto',nu=0.59, coef0=0.053)\n",
    "        clf_NuSVC.fit(train4p[train_index,:],train2p.loc[train_index]['target'])\n",
    "        oof_NuSVC[idx1[test_index3]] = clf_NuSVC.predict_proba(train4[test_index3,:])[:,1]\n",
    "        preds_NuSVC[test2.index] += clf_NuSVC.predict_proba(test4)[:,1] / skf.n_splits\n",
    "        \n",
    "    if k%64==0:     \n",
    "        print(k, 'QDA oof auc : ', round(roc_auc_score(train['target'][idx1], oof_QDA[idx1]), 5))\n",
    "        print(k, 'NuSVC oof auc : ', round(roc_auc_score(train['target'][idx1], oof_NuSVC[idx1]), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Labeled QDA scores CV = 0.96953\n",
      "Pseudo Labeled QDA scores CV = 0.96918\n"
     ]
    }
   ],
   "source": [
    "# PRINT CV AUC\n",
    "auc_QDA = roc_auc_score(train['target'],oof_QDA)\n",
    "print('Pseudo Labeled QDA scores CV =',round(auc_QDA,5))\n",
    "\n",
    "auc_NuSVC = roc_auc_score(train['target'],oof_NuSVC)\n",
    "print('Pseudo Labeled QDA scores CV =',round(auc_NuSVC,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = pd.DataFrame(np.concatenate((oof_SVC.reshape(-1,1),oof_NuSVC.reshape(-1,1),oof_KNN.reshape(-1,1),oof_QDA.reshape(-1,1),oof_LR.reshape(-1,1),oof_MLP.reshape(-1,1)), axis=1))\n",
    "test_new = pd.DataFrame(np.concatenate((preds_SVC.reshape(-1,1),preds_NuSVC.reshape(-1,1),preds_KNN.reshape(-1,1),preds_QDA.reshape(-1,1),preds_LR.reshape(-1,1),preds_MLP.reshape(-1,1)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's auc: 0.973928\tvalid_1's auc: 0.970491\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's auc: 0.971876\tvalid_1's auc: 0.970889\n",
      "0.9708892341936597\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's auc: 0.973569\tvalid_1's auc: 0.972654\n",
      "[400]\ttraining's auc: 0.975669\tvalid_1's auc: 0.972724\n",
      "Early stopping, best iteration is:\n",
      "[339]\ttraining's auc: 0.975164\tvalid_1's auc: 0.972766\n",
      "0.9727664634422418\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's auc: 0.973633\tvalid_1's auc: 0.972336\n",
      "[400]\ttraining's auc: 0.975738\tvalid_1's auc: 0.972277\n",
      "Early stopping, best iteration is:\n",
      "[222]\ttraining's auc: 0.973936\tvalid_1's auc: 0.972399\n",
      "0.9723989866598901\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's auc: 0.974155\tvalid_1's auc: 0.970047\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's auc: 0.972427\tvalid_1's auc: 0.970129\n",
      "0.9701288859951808\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's auc: 0.973647\tvalid_1's auc: 0.971594\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttraining's auc: 0.973513\tvalid_1's auc: 0.971635\n",
      "0.9716352381333736\n",
      "LGB auc:  0.97151\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'bagging_freq': 3,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'boost_from_average':'False',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 1,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 10,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 82,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 10,\n",
    "    'objective': 'binary', \n",
    "    'verbosity': 1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "import lightgbm as lgb\n",
    "N = 5\n",
    "skf_lgb = StratifiedKFold(n_splits=N, random_state=42)\n",
    "\n",
    "oof_lgb = np.zeros(train_new.shape[0])\n",
    "pred_stack = np.zeros(len(test_new))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf_lgb.split(train_new, train['target'])):\n",
    "    print(\"Fold {}\".format(fold_+1))\n",
    "    x_train, y_train = train_new.iloc[trn_idx], train['target'].iloc[trn_idx]\n",
    "    x_val, y_val = train_new.iloc[val_idx], train['target'].iloc[val_idx]\n",
    "    x_train.head()\n",
    "    \n",
    "    trn_data = lgb.Dataset(x_train, label=y_train)\n",
    "    val_data = lgb.Dataset(x_val, label=y_val)\n",
    "    classifier = lgb.train(param, trn_data, 100000, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 200)\n",
    "\n",
    "    val_pred = classifier.predict(x_val, num_iteration=classifier.best_iteration)\n",
    "    oof_lgb[val_idx] = val_pred\n",
    "    pred_stack += classifier.predict(test_new, num_iteration=classifier.best_iteration) / N\n",
    "    print(roc_auc_score(y_val, val_pred))\n",
    "\n",
    "auc_lgb = roc_auc_score(train['target'],oof_lgb)\n",
    "print('LGB auc: ',round(auc_lgb,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_stack = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "submission_stack['target'] = pred_stack\n",
    "submission_stack.head()\n",
    "submission_stack.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new.to_csv('train_new.csv', index=False)\n",
    "test_new.to_csv('test_new.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
